{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "ds = pd.read_csv(\"drug200.csv\")\n",
    "ds.head(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Na_to_K</th>\n",
       "      <th>Drug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>8.607</td>\n",
       "      <td>drugX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>16.275</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>11.037</td>\n",
       "      <td>drugC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>15.171</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>19.368</td>\n",
       "      <td>drugY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  Na_to_K   Drug\n",
       "0   23   F    HIGH        HIGH   25.355  drugY\n",
       "1   47   M     LOW        HIGH   13.093  drugC\n",
       "2   47   M     LOW        HIGH   10.114  drugC\n",
       "3   28   F  NORMAL        HIGH    7.798  drugX\n",
       "4   61   F     LOW        HIGH   18.043  drugY\n",
       "5   22   F  NORMAL        HIGH    8.607  drugX\n",
       "6   49   F  NORMAL        HIGH   16.275  drugY\n",
       "7   41   M     LOW        HIGH   11.037  drugC\n",
       "8   60   M  NORMAL        HIGH   15.171  drugY\n",
       "9   43   M     LOW      NORMAL   19.368  drugY"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "ds[\"Drug\"].hist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 156
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "#3 Plot the distribution of the instances in each class and store the graphic in a file calles drug-distribution.pdf\n",
    "# Description of the dataset\n",
    "print('SHAPE OF DATASET: ', ds.shape, '\\n\\nCOLUMNS IN DATASET: ', ds.columns,'\\n\\nDrug ClASS IN DATASET: ',ds.Drug.unique(),)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SHAPE OF DATASET:  (200, 6) \n",
      "\n",
      "COLUMNS IN DATASET:  Index(['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K', 'Drug'], dtype='object') \n",
      "\n",
      "Drug ClASS IN DATASET:  ['drugY' 'drugC' 'drugX' 'drugA' 'drugB']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "#first count each class then print bar graph\n",
    "plt.title(\"drug-distribution graph\")\n",
    "plt.xlabel('Drug Class')\n",
    "plt.ylabel(\"Count\")\n",
    "print(ds[\"Drug\"].hist())\n",
    "\n",
    "plt.savefig('drug-Distribution.pdf')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "#Grouping and perform count over each drug class\n",
    "num =  ds.groupby('Drug')['Drug'].count()\n",
    "print(num)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drug\n",
      "drugA    23\n",
      "drugB    16\n",
      "drugC    16\n",
      "drugX    54\n",
      "drugY    91\n",
      "Name: Drug, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Replacing categorical values of Sex column by dummy variables (Because it is independent category i.e. No one is higher or lower)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "#use dummies 特征提取 one hot encode\n",
    "dummy_variable_sex = pd.get_dummies(ds.Sex)\n",
    "# Concatenate \n",
    "data = pd.concat([ds, dummy_variable_sex], axis=1)\n",
    "print(data.head(5))\n",
    "# Drop sex column\n",
    "data.drop(\"Sex\", axis = 1, inplace=True)\n",
    "print(data.head(5))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Age Sex      BP Cholesterol  Na_to_K   Drug  F  M\n",
      "0   23   F    HIGH        HIGH   25.355  drugY  1  0\n",
      "1   47   M     LOW        HIGH   13.093  drugC  0  1\n",
      "2   47   M     LOW        HIGH   10.114  drugC  0  1\n",
      "3   28   F  NORMAL        HIGH    7.798  drugX  1  0\n",
      "4   61   F     LOW        HIGH   18.043  drugY  1  0\n",
      "   Age      BP Cholesterol  Na_to_K   Drug  F  M\n",
      "0   23    HIGH        HIGH   25.355  drugY  1  0\n",
      "1   47     LOW        HIGH   13.093  drugC  0  1\n",
      "2   47     LOW        HIGH   10.114  drugC  0  1\n",
      "3   28  NORMAL        HIGH    7.798  drugX  1  0\n",
      "4   61     LOW        HIGH   18.043  drugY  1  0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "#Extracting target variable  提取列数据 \n",
    "y = data.iloc[:, -3].values #take Drug column "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "# Dropping Drug column\n",
    "dataset = data.drop(\"Drug\", axis = 1, inplace=False)\n",
    "print(dataset.head(5))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "   Age      BP Cholesterol  Na_to_K  F  M\n",
      "0   23    HIGH        HIGH   25.355  1  0\n",
      "1   47     LOW        HIGH   13.093  0  1\n",
      "2   47     LOW        HIGH   10.114  0  1\n",
      "3   28  NORMAL        HIGH    7.798  1  0\n",
      "4   61     LOW        HIGH   18.043  1  0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Replacing categorical values of BP and Cholesterol column by Label encoder (Because this is dependent ie higher and lower)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "# Converting dataframe into arrays\n",
    "dataset_array = dataset.values\n",
    "dataset_array"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[23, 'HIGH', 'HIGH', 25.355, 1, 0],\n",
       "       [47, 'LOW', 'HIGH', 13.093, 0, 1],\n",
       "       [47, 'LOW', 'HIGH', 10.114, 0, 1],\n",
       "       ...,\n",
       "       [52, 'NORMAL', 'HIGH', 9.894, 0, 1],\n",
       "       [23, 'NORMAL', 'NORMAL', 14.02, 0, 1],\n",
       "       [40, 'LOW', 'NORMAL', 11.349, 1, 0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "# Using sklearn library's LabelEncoder class\n",
    "# Encode BP label with value between 0 and n_classes-1\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_BP = LabelEncoder()\n",
    "le_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
    "dataset_array[:,1] = le_BP.transform(dataset_array[:,1])\n",
    "dataset_array"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[23, 0, 'HIGH', 25.355, 1, 0],\n",
       "       [47, 1, 'HIGH', 13.093, 0, 1],\n",
       "       [47, 1, 'HIGH', 10.114, 0, 1],\n",
       "       ...,\n",
       "       [52, 2, 'HIGH', 9.894, 0, 1],\n",
       "       [23, 2, 'NORMAL', 14.02, 0, 1],\n",
       "       [40, 1, 'NORMAL', 11.349, 1, 0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "# Using sklearn library's LabelEncoder class\n",
    "# Encode Cholesterol label with value between 0 and n_classes-1\n",
    "le_Chole = LabelEncoder()\n",
    "le_Chole.fit([ 'LOW', 'NORMAL', 'HIGH'])\n",
    "print(le_Chole.transform(['LOW', 'NORMAL', 'HIGH']))\n",
    "dataset_array[:,2] = le_Chole.transform(dataset_array[:,2])\n",
    "X = dataset_array\n",
    "X"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 0]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[23, 0, 0, 25.355, 1, 0],\n",
       "       [47, 1, 0, 13.093, 0, 1],\n",
       "       [47, 1, 0, 10.114, 0, 1],\n",
       "       ...,\n",
       "       [52, 2, 0, 9.894, 0, 1],\n",
       "       [23, 2, 2, 14.02, 0, 1],\n",
       "       [40, 1, 2, 11.349, 1, 0]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#Splitting the dataset into the Train set and Test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#NB:a Gaussian Naive Bayes Classifier (naivebayes.GaussianNB) with the default parameters.\n",
    "\n",
    "#naivebayes.GaussianNB"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "f=open('drugs-performance.txt','w')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# a)GaussianNB default parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "# GaussianNB Naive Bayes\n",
    "print(\"--------------------------------GaussianNB default values-----------------------------------\", file=f)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = gnb.predict(X_test)\n",
    "# predict probabilities, Return probability estimates for the test vector X.\n",
    "y_pred_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# b) confusion matrix\n",
    "from sklearn import metrics\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion, file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \", file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class),file=f)\n",
    "\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \", file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy), file=f)\n",
    "\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# b)Base-DT classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "# Decision Tree\n",
    "print(\"--------------------------------Decision Tree default values-----------------------------------\", file=f)\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "#Create a Decision Tree Classifier\n",
    "mod2 = DecisionTreeClassifier()\n",
    "\n",
    "#Train the model using the training sets\n",
    "mod2.fit(X_train, y_train)\n",
    "\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = mod2.predict(X_test)\n",
    "# predict probabilities, Return probability estimates for the test vector X.\n",
    "y_pred_proba = mod2.predict_proba(X_test)\n",
    "\n",
    "# b) confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion, file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \", file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class),file=f)\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \", file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy), file=f)\n",
    "\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# c) Top-DT \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    " # GridSearchCV\n",
    " # find the best combination of hyper-parameters\n",
    " # as determined by the evalustion function that you have determined in step3\n",
    "\n",
    "print(\"--------------------------------Top-DT hyperoarameter values-----------------------------------\", file=f)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Create a Decision tree Classifier\n",
    "mod3 = DecisionTreeClassifier()\n",
    "params = {'criterion': ['gini','entropy'],'max_depth':[3,5],'min_samples_split':[3,5,7]}\n",
    "#Create the grid search object\n",
    "grid = GridSearchCV(mod3, param_grid=params, cv=5)\n",
    "#Fit the grid search objet to the data to compute the optimal model\n",
    "grid = grid.fit(X_train, y_train)\n",
    "print('best_estimator:', grid.best_params_, 'best_score:', grid.best_score_, file=f)\n",
    "\n",
    "\n",
    "\n",
    "# use best combination of hyper-parameters to train X\n",
    "mod3_best = grid.best_estimator_\n",
    "mod3_best.fit(X_train, y_train)\n",
    "\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = mod3_best.predict(X_test)\n",
    "#print('train score: ', mod3_best.score(X_train,y_train), 'test score: ', mod3_best.score(X_test,y_test))\n",
    "\n",
    "\n",
    "# b) confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion, file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \", file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class),file=f)\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \", file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy), file=f)\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# d) PER: Perceptron(linear_model.Perceptron) with default parameter values\n",
    " "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "\n",
    "print(\"--------------------------------PER with default parameter values-----------------------------------\", file=f)\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# create Perceptron()\n",
    "mod4 = Perceptron()\n",
    "\n",
    "# fit training dataset\n",
    "mod4.fit(X_train, y_train)\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = mod4.predict(X_test)\n",
    "\n",
    "# b) confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion, file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \", file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class), file=f)\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \", file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy), file=f)\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# e) Base-MLP:(neural_network.MLPClassifier) with 1 hidden layer of 100 neurons, sigmoid/logistic as activation function , stochastic gradient descent and default values for the rest of parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "print(\"--------------------------------Base-MLP with default parameter values-----------------------------------\",file=f)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# create MLP classifier\n",
    "mod5 = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "\n",
    "# fit training dataset\n",
    "mod5.fit(X_train, y_train)\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = mod5.predict(X_test)\n",
    "\n",
    "# b) confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion, file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \", file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class), file=f)\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \", file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy), file=f)\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# f) TOP-MLP \n",
    "2 hidden layer with 30+50 nodes, or 3 hidden layer with 10+10+10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "# GridSearchCV\n",
    " # find the best combination of hyper-parameters\n",
    " # as determined by the evalustion function that you have determined in step3\n",
    "\n",
    "print(\"--------------------------------Top-MLP hyperoarameter values-----------------------------------\", file=f)\n",
    "\n",
    "\n",
    "#Create a base MLP Classifier\n",
    "mod6 = MLPClassifier()\n",
    "params = {  'hidden_layer_sizes': [(30,50,), (10,10,10,)],\n",
    "    'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'solver': ['adam', 'sgd']}\n",
    "#Create the grid search object\n",
    "grid = GridSearchCV(mod6, param_grid=params)\n",
    "#Fit the grid search objet to the data to compute the optimal model\n",
    "grid = grid.fit(X_train, y_train)\n",
    "print('a) best parameter:', grid.best_params_,file=f)\n",
    "hidden_layer_sizes_ = grid.best_params_['hidden_layer_sizes']\n",
    "activation_= grid.best_params_['activation']\n",
    "solver_= grid.best_params_['solver']\n",
    "# use best combination of hyper-parameters to train X\n",
    "mod6_best=MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_,activation=activation_,solver=solver_)\n",
    "mod6_best.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "y_pred_class = mod6_best.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# b) confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(\"(b) the confusion matrix: \", file=f)\n",
    "print(confusion,file=f)\n",
    "\n",
    "# c) the precision, recall and F1-measure for each class\n",
    "print(\"(c) the precision, recall and F1-measure for each class of the test set : \",file=f)\n",
    "print(metrics.classification_report(y_test, y_pred_class),file=f)\n",
    "\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \",file=f)\n",
    "print(\"Accuracy score of the test set is : \" + str(accuracy),file=f)\n",
    "macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1),file=f)\n",
    "weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1),file=f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "import statistics\n",
    "a=[]\n",
    "for i in range(5):\n",
    "    a.append(i)\n",
    "print(statistics.stdev(a))\n",
    "\n",
    " \n",
    "# creating a simple data - set\n",
    "sample = [1,1,1,1,1]\n",
    " \n",
    "# Prints standard deviation\n",
    "# xbar is set to default value of 1\n",
    "print(\"Standard Deviation of sample is  \"+ str(statistics.stdev(sample)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.5811388300841898\n",
      "Standard Deviation of sample is  0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# repeat 10 times"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "import statistics \n",
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************',file=f)\n",
    "print(\"************************this is 10 times***************************************\",file=f)\n",
    "print(\"********************************************************************************\",file=f)\n",
    "print(\"--------------------------------GaussianNB default values-----------------------------------\", file=f)\n",
    "    \n",
    "for i in range(10):\n",
    "   \n",
    "#Create a Gaussian Classifier\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "    gnb.fit(X_train, y_train)\n",
    "\n",
    "# predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = gnb.predict(X_test)\n",
    "# predict probabilities, Return probability estimates for the test vector X.\n",
    "    y_pred_proba = gnb.predict_proba(X_test)\n",
    "\n",
    "# b) confusion matrix\n",
    "\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "# d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    a.append(accuracy)\n",
    "    totalAccuray+=accuracy\n",
    " \n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "    m.append(macro_avg_F1)\n",
    "    totalMacro+=macro_avg_F1\n",
    "  \n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************',file=f)\n",
    "\n",
    "        # Decision Tree\n",
    "print(\"--------------------------------Decision Tree default values-----------------------------------\", file=f)\n",
    "    \n",
    "for i in range(10):\n",
    "    \n",
    "    #Create a Decision Tree Classifier\n",
    "    mod2 = DecisionTreeClassifier()\n",
    "\n",
    "    #Train the model using the training sets\n",
    "    mod2.fit(X_train, y_train)\n",
    "\n",
    "    # predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = mod2.predict(X_test)\n",
    "    # predict probabilities, Return probability estimates for the test vector X.\n",
    "    y_pred_proba = mod2.predict_proba(X_test)\n",
    "\n",
    "    # b) confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "\n",
    "    # d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    \n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "    \n",
    "    \n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "    a.append(accuracy)\n",
    "    m.append(macro_avg_F1)\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalAccuray+=accuracy\n",
    "    totalMacro+=macro_avg_F1\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************')\n",
    "print(\"--------------------------------Top-DT hyperoarameter values-----------------------------------\", file=f)\n",
    "\n",
    "for i in range(10):    \n",
    "    \n",
    "    #Create a Decision tree Classifier\n",
    "    mod3 = DecisionTreeClassifier()\n",
    "    params = {'criterion': ['gini','entropy'],'max_depth':[3,5],'min_samples_split':[3,5,7]}\n",
    "    #Create the grid search object\n",
    "    grid = GridSearchCV(mod3, param_grid=params, cv=5)\n",
    "    #Fit the grid search objet to the data to compute the optimal model\n",
    "    grid = grid.fit(X_train, y_train)\n",
    "  \n",
    "\n",
    "    # use best combination of hyper-parameters to train X\n",
    "    mod3_best = grid.best_estimator_\n",
    "    mod3_best.fit(X_train, y_train)\n",
    "\n",
    "    # predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = mod3_best.predict(X_test)\n",
    "    #print('train score: ', mod3_best.score(X_train,y_train), 'test score: ', mod3_best.score(X_test,y_test))\n",
    "\n",
    "\n",
    "    # b) confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "   \n",
    "    # c) the precision, recall and F1-measure for each class\n",
    "  \n",
    "\n",
    "    # d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    \n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "\n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "    \n",
    "    a.append(accuracy)\n",
    "    m.append(macro_avg_F1)\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalAccuray+=accuracy\n",
    "    totalMacro+=macro_avg_F1\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************')\n",
    "print(\"--------------------------------PER with default parameter values-----------------------------------\", file=f)\n",
    "\n",
    "for i in range(10):\n",
    "   \n",
    "    # create Perceptron()\n",
    "    mod4 = Perceptron()\n",
    "\n",
    "    # fit training dataset\n",
    "    mod4.fit(X_train, y_train)\n",
    "    # predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = mod4.predict(X_test)\n",
    "\n",
    "    # b) confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "   \n",
    "\n",
    "    # c) the precision, recall and F1-measure for each class\n",
    "  \n",
    "\n",
    "    # d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "  \n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "  \n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "  \n",
    "    a.append(accuracy)\n",
    "    m.append(macro_avg_F1)\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalAccuray+=accuracy\n",
    "    totalMacro+=macro_avg_F1\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************')\n",
    "print(\"--------------------------------Base-MLP with default parameter values-----------------------------------\",file=f)\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    # create MLP classifier\n",
    "    mod5 = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "\n",
    "    # fit training dataset\n",
    "    mod5.fit(X_train, y_train)\n",
    "    # predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = mod5.predict(X_test)\n",
    "\n",
    "    # b) confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "  \n",
    "    # c) the precision, recall and F1-measure for each class\n",
    "  \n",
    "\n",
    "    # d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    \n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    "   # print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1), file=f)\n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "    #print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1), file=f)\n",
    "    GridSearchCV\n",
    "    # find the best combination of hyper-parameters\n",
    "    # as determined by the evalustion function that you have determined in step3\n",
    "    a.append(accuracy)\n",
    "    m.append(macro_avg_F1)\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalAccuray+=accuracy\n",
    "    totalMacro+=macro_avg_F1\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "\n",
    "totalAccuray=0\n",
    "totalMacro=0\n",
    "totalWeight=0\n",
    "a=[]\n",
    "m=[]\n",
    "w=[]\n",
    "print('**************************************************************************************')\n",
    "print(\"--------------------------------Top-MLP hyperoarameter values-----------------------------------\", file=f)\n",
    "for i in range(10):\n",
    "    #Create a base MLP Classifier\n",
    "    mod6 = MLPClassifier()\n",
    "    params = {  'hidden_layer_sizes': [(30,50,), (10,10,10,)],\n",
    "        'activation': ['logistic', 'tanh', 'relu', 'identity'],\n",
    "        'solver': ['adam', 'sgd']}\n",
    "    #Create the grid search object\n",
    "    grid = GridSearchCV(mod6, param_grid=params)\n",
    "    #Fit the grid search objet to the data to compute the optimal model\n",
    "    grid = grid.fit(X_train, y_train)\n",
    "    #print('a) best parameter:', grid.best_params_,file=f)\n",
    "    hidden_layer_sizes_ = grid.best_params_['hidden_layer_sizes']\n",
    "    activation_= grid.best_params_['activation']\n",
    "    solver_= grid.best_params_['solver']\n",
    "    # use best combination of hyper-parameters to train X\n",
    "    mod6_best=MLPClassifier(hidden_layer_sizes=hidden_layer_sizes_,activation=activation_,solver=solver_)\n",
    "    mod6_best.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    # predict, Perform classification on an array of test vectors X.\n",
    "    y_pred_class = mod6_best.predict(X_test)\n",
    "\n",
    "    # b) confusion matrix\n",
    "    confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "   \n",
    "    # c) the precision, recall and F1-measure for each class\n",
    "    \n",
    "\n",
    "    # d) the accuracy, macro-average F1 and weighted-average F1 of the model\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred_class)\n",
    " #   print(\"(d) the accuracy, macro-average F1 and weighted-average F1 of the model: \",file=f)\n",
    "  #  print(\"Accuracy score of the test set is : \" + str(accuracy),file=f)\n",
    "    macro_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='macro')\n",
    " #   print(\"Macro average F1 of the test set is : \" + str(macro_avg_F1),file=f)\n",
    "    weighted_avg_F1 = metrics.f1_score(y_test, y_pred_class, average='weighted')\n",
    "  #  print(\"Weighted average F1 of the test set is : \" + str(weighted_avg_F1),file=f)\n",
    "    a.append(accuracy)\n",
    "    m.append(macro_avg_F1)\n",
    "    w.append(weighted_avg_F1)\n",
    "    totalAccuray+=accuracy\n",
    "    totalMacro+=macro_avg_F1\n",
    "    totalWeight+=weighted_avg_F1\n",
    "    \n",
    "print(\"the list of accuracy\"+str(a), file=f)\n",
    "print(\"average of accuracy score of hte test set is :\"+str(totalAccuray/10), file=f)\n",
    "print(\"standard deviation for accuracy: \"+str(statistics.stdev(a)), file=f)\n",
    "print(\"the list of Macro average F1\"+str(m), file=f)\n",
    "print(\"average of Macro average F1 of the test set is : \" + str(totalMacro/10), file=f)\n",
    "print(\"standard deviation for Macro average F1: \"+str(statistics.stdev(m)), file=f)\n",
    "print(\"the list of weight average F1: \"+str(w), file=f)\n",
    "print(\"average of Weighted average F1 of the test set is : \" + str(totalWeight/10), file=f)\n",
    "print(\"standard deviation for weight average F1: \"+str(statistics.stdev(w)), file=f)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**************************************************************************************\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8fce6691405556ffb3062e1861de211962c440fc65c8599586c6206ef07fdf2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}